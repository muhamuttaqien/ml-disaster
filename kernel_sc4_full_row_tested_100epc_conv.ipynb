{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d447facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ae3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7b137a",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e9669a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./per_station.xlsx\"\n",
    "data = pd.read_excel(data_path)\n",
    "\n",
    "# Extract the 'sc4' column data\n",
    "sc_data = data['sc4'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy data\n",
    "series_data = sc_data[:]\n",
    "\n",
    "# Plot the dummy data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(series_data, linestyle='-')\n",
    "plt.title('Tsunami Simulation Data (Scenario 4)')\n",
    "plt.xlabel('Period')\n",
    "plt.ylabel('Attribute')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e975d7",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd1dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Define sequence length\n",
    "sequence_length = 20\n",
    "\n",
    "# Prepare the data\n",
    "X, y = prepare_data(series_data, sequence_length)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.Tensor(X).unsqueeze(-1)  # Add an extra dimension for the input channel\n",
    "y_tensor = torch.Tensor(y).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a608c",
   "metadata": {},
   "source": [
    "## LSTM Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf31e7c1",
   "metadata": {},
   "source": [
    "#### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef0975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(ConvLSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Define the ConvLSTM layer\n",
    "        self.conv_lstm = nn.ConvLSTM2d(input_size=1, hidden_size=hidden_size, kernel_size=(3, 3), num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Define the fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply ConvLSTM layer\n",
    "        out, _ = self.conv_lstm(x.unsqueeze(2).unsqueeze(2))  # Add channel and spatial dimensions\n",
    "        \n",
    "        # Take the output of the last time step\n",
    "        out = out[:, -1, :, :, :]\n",
    "        \n",
    "        # Reshape for fully connected layer\n",
    "        out = out.view(out.size(0), -1)\n",
    "        \n",
    "        # Apply fully connected layer\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Define model parameters\n",
    "input_size = 1\n",
    "hidden_size = 32\n",
    "num_layers = 2  # Set the number of layers in the ConvLSTM stack\n",
    "output_size = 1\n",
    "\n",
    "# Instantiate the model\n",
    "model = ConvLSTM(input_size, hidden_size, num_layers, output_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b12bc86",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708d0536",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Store losses\n",
    "losses = []\n",
    "\n",
    "# Initialize the best loss as infinity\n",
    "best_loss = float('inf')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # Shuffle the data and split into batches\n",
    "    indices = torch.randperm(len(X_tensor))\n",
    "    X_shuffled = X_tensor[indices]\n",
    "    y_shuffled = y_tensor[indices]\n",
    "    \n",
    "    for i in range(0, len(X_tensor), batch_size):\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X_shuffled[i:i+batch_size])\n",
    "        loss = criterion(outputs, y_shuffled[i:i+batch_size])\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss for the epoch\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    # Average epoch loss\n",
    "    epoch_loss /= (len(X_tensor) / batch_size)\n",
    "    losses.append(epoch_loss)\n",
    "    \n",
    "    # Save the model if this epoch's loss is the best we've seen so far\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], MSE Loss: {epoch_loss:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e900ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curve\n",
    "offset = 30\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(offset+1, num_epochs+1), losses[offset:], linestyle='-')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdf0331",
   "metadata": {},
   "source": [
    "#### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48f1ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the first sequence for prediction\n",
    "first_sequence = torch.FloatTensor(series_data[:sequence_length]).unsqueeze(0).unsqueeze(-1)\n",
    "\n",
    "# Make predictions for the entire time series\n",
    "with torch.no_grad():\n",
    "    future_periods = len(series_data) - sequence_length\n",
    "    future_data = series_data[:sequence_length].tolist()\n",
    "\n",
    "    for i in range(future_periods):\n",
    "        pred = model(first_sequence)\n",
    "        future_data.append(pred.item())\n",
    "        \n",
    "        # Update the first sequence for the next prediction\n",
    "        # first_sequence = torch.cat((first_sequence[:, 1:, :], pred.unsqueeze(-1)), dim=1)\n",
    "        first_sequence = torch.cat((first_sequence[:, 1:, :], torch.tensor([[series_data[i+sequence_length]]], dtype=torch.float32).unsqueeze(0)), dim=1)\n",
    "        \n",
    "# Plot the original and predicted simulation data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.arange(len(series_data)), series_data, linestyle='-', label='Simulation Data')\n",
    "plt.plot(np.arange(len(series_data)), future_data, linestyle='--', color='g', label='Predicted Data')\n",
    "plt.title('Tsunami Simulation Data Prediction with LSTM')\n",
    "plt.xlabel('Period')\n",
    "plt.ylabel('Attribute')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original and predicted simulation data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.arange(len(series_data[:3000])), series_data[:3000], linestyle='-', label='Simulation Data')\n",
    "plt.plot(np.arange(len(series_data[:3000])), future_data[:3000], linestyle='--', color='g', label='Predicted Data')\n",
    "plt.title('Tsunami Simulation Data Prediction with LSTM')\n",
    "plt.xlabel('Period')\n",
    "plt.ylabel('Attribute')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674324f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(series_data[sequence_length:], future_data[sequence_length:])\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(series_data[sequence_length:], future_data[sequence_length:])\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495311c7",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
